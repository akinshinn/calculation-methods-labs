\documentclass{article}
\usepackage[T2A]{fontenc}
\usepackage{epigraph}
\usepackage[english, russian]{babel} % языковой пакет
\usepackage{amsmath,amsfonts,amssymb} %математика
\usepackage{mathtools}
\usepackage[oglav,spisok,boldsect,eqwhole,figwhole,hyperref,hyperprint,remarks,greekit]{../../style/fn2kursstyle}
\usepackage[utf8]{inputenc}
\usepackage[]{tkz-euclide}
\usepackage{algpseudocode}
\usepackage{pgfplots}
\usepackage{tikz-3dplot}
\usepackage[oglav,spisok,boldsect,eqwhole,figwhole,hyperref,hyperprint,remarks,greekit]{./style/fn2kursstyle}
\usepackage{multirow}
\usepackage{supertabular}
\usepackage{multicol}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{float}
\usepackage{graphicx}
\pgfplotsset{compat=1.9}
\usepackage[svgnames]{pstricks}
\usepackage{pst-solides3d} 
\usepackage{multirow}
\usepackage{hhline}
\usepackage{slashbox}
\usepackage{pdflscape}
\usepackage{array} 
\graphicspath{{../../style/}}

  



\newcommand{\cond}{\mathop{\mathrm{cond}}\nolimits}
\newcommand{\rank}{\mathop{\mathrm{rank}}\nolimits}
% Переопределение команды \vec, чтобы векторы печатались полужирным курсивом
\renewcommand{\vec}[1]{\text{\mathversion{bold}${#1}$}}%{\bi{#1}}
\newcommand\thh[1]{\text{\mathversion{bold}${#1}$}}
%Переопределение команды нумерации перечней: точки заменяются на скобки
\renewcommand{\labelenumi}{\theenumi)}
\newtheorem{theorem}{Теорема}
\newtheorem{define}{Определение}
\tdplotsetmaincoords{60}{115}
\pgfplotsset{compat=newest}

\title{Итерационные методы решения систем
линейных алгебраических уравнений}
\author{Н.\,О.~Акиньшин}
\group{ФН2-51Б}
\date{2024}
\supervisor{А.\,С.~Джагарян}



\begin{document}
    \maketitle
    \newpage
    \tableofcontents
    \newpage

    \section{Контрольные вопросы}
    \begin{enumerate}
        \item Почему нельзя находить собственные числа матрицы $A$,
        прямо решая уравнение \mbox{$\det (A - \lambda E) = 0 $}, а собственные
        векторы — «по определению», решая систему $ ( A - \lambda E)e_j = 0$?
        \newline 
        {\bfseries Ответ. } Исходя из уравнения $\det (A - \lambda E) = 0 $, матрица 
        $A - \lambda E$ должна быть вырожденной, однако в силу того, что все измерения проводятся 
        с некоторой погрешностью и все числа в компьютере хранятся тоже с некоторой ошибкой, то 
        матрица $A - \lambda E$ почти никогда не будет вырожденной. Также стоит добавить, что 
        нахождение определителя матриц больших размерностей задача очень трудная с вычислительной 
        точки зрения. 
        \item Докажите, что ортогональное преобразование подобия со-
        храняет симметрию матрицы.
        \newline
        {\bfseries Ответ. } 
	Пусть имеем матрицу A--симметричная т.е. $A^T=A$ и ортогональное преобразование Q т.е. $Q^T=Q^{-1}$. Тогда подобная матрица B, полученная ортогональным  преобразованием т.е. $B=Q^{-1} \cdot A \cdot Q$ в силу ортогональности $B=Q^T \cdot A \cdot Q$. Транспонируем обе части и используем $A^T=A$, тогда получим $B^T = Q^T \cdot A^T \cdot Q = Q^T \cdot A \cdot Q=B$.
        \item Как преобразование подобия меняет собственные векторы
        матрицы?
        \newline
        {\bfseries Ответ. } 
        В ходе преобразования 
        \begin{equation*}
            B = P^{-1} A P
        \end{equation*}
        собственный вектор $u$ матрицы $A$ , соответствующий собственному значению $\lambda$, меняется следующим образом
        \begin{equation*}
            v = P^{-1} u.
        \end{equation*}
        Если считать $P$ матрицей перехода, то это означает, что вектор $u$ переходит в другой базис, то есть растягивается или поворачивается. 

        \item Почему на практике матрицу $A$ подобными преобразовани-
        ями вращения приводят только к форме Хессенберга, но
        не к треугольному виду?
        \newline 
        {\bfseries Ответ. } 
        Заметим следующее, матрица поворота $T_{kl}$--ортогональна и преобразует исходную матрицу по следующему закону $A^*= T_{kl} \cdot A \cdot T_{kl}^T$. Такой поворот обращает в ноль следующий коэффициент $a^*_{l,k-1}$. Матрица $T_{kl}$ состоит из нулей, кроме $T^{kk}_{kl}, TT^{kl}_{kl}, T^{lk}_{kl}, T^{ll}_{kl}, T^{ii}_{kl}\, \forall i$ (верхние индексы обозначают соответствующие координаты матрицы). Если требуется обнулить коэффициенты под главной диагональю, тогда $a^*_{i,i-1}=0 \, \forall i$ т.е. $l=i=k$ т.е. требуется совершить следующее преобразование $A^*= T_{ii} \cdot A \cdot T_{ii}^T$. Однако матрица $T_{ii}$ не существует т.к. она определяется для разных индексов. Таким образом после приведение матрицы данными преобразованиями к виду Хессенберга нужно будет придумать какое-то другое преобразование обнуляющее коэффициенты под главной диагональю, что может вызвать вычислительные сложности т.е. такой алгоритм будет работать дольше чем QR разложение.
        \item Оцените количество арифметических операций, необходи-
        мое для приведения произвольной квадратной матрицы $A$
        к форме Хессенберга.
        \newline 
        {\bfseries Ответ. } 
        Рассмотрим алгоритм приведения произвольной квадратной матрицы A к форме Хессенберга.
	
	
	\noindent HesenbergDecomposition(Matrix)
	
	\begin{algorithmic}[1]
		\State prod=0, $\alpha=0, \, \beta=0$, koren=0, tmp1=0, tmp2=0
		\For{k = 1; k < size - 1; k++}
			\For{l = k+1; l < size; l++}
				\State $koren = \sqrt{Matrix[l][k - 1] * Matrix[l][k - 1] + Matrix[k][k - 1] * Matrix[k][k - 1]}$
				\State $\alpha = \frac{Matrix[k][k - 1]}{koren}$
				\State $\beta = \frac{Matrix[l][k - 1]}{koren}$
				\For{index = k-1; index < size; index++}
					\State tmp1 = alpha * Matrix[k][index] + beta * Matrix[l][index]
					\State tmp2 = alpha * Matrix[l][index] - beta * Matrix[k][index]
					\State Matrix[k][index] = tmp1
					\State Matrix[l][index] = tmp2
					
				\EndFor
				\For{index = 0; index < size; index++}
					\State tmp1 = alpha * Matrix[index][k] + beta * Matrix[index][l]
					\State tmp2 = alpha * Matrix[index][l] - beta * Matrix[index][k]
					\State Matrix[index][k] = tmp1
					\State Matrix[index][l] = tmp2
				\EndFor
			\EndFor
		\EndFor
	\end{algorithmic}
	
	Таким образом количество умножений можно вычислить по следующей формуле 
	\[
	prod = \sum_{k=1}^{n-2} \sum_{l=k+1}^{n-1} (4+\sum_{i=k-1}^{n-1} 4 + \sum_{i=0}^{n-1} 4=\frac{2}{3} (5n^3-9n^2-8n+12)
	\]
        \item Сойдется ли алгоритм обратных итераций, если в качестве
        начального приближения взять собственный вектор, соответствующий
         другому собственному значению? Что будет
        в этой ситуации в методе обратной итерации, использующем
        отношение Рэлея? Привести пример.
        \newline 
        {\bfseries Ответ. } 
        Рассмотрим обычный метод обратной итерации. 
        Пусть $\sigma_m$ -- приближенное число к некоторому собственному значению $\lambda_m$,
        $x_0^j$ -- собственный вектор, соответствующий собственному значению $\lambda_j \neq \lambda_m$.
        Тогда рассмотрим
        \begin{equation*}
            (A - \sigma_m E) y_{k+1} = x_k.
        \end{equation*}
        Заметим 
        \begin{equation*}
            y_{k+1} = (A - \sigma_m E)^{-k} x^j_0
        \end{equation*}
        Для произвольного вектора $x$
        \begin{equation*}
            (A - \sigma_m E)^{-k} x = (\lambda_m - \sigma_m)^{-k} \left(
                \xi_m \boldsymbol{e_m} + \sum_{i=1; i \neq m}^{n} \left(\dfrac{\lambda_m - \sigma_m}{\lambda_i - \sigma_m}\right)^k \xi_i \boldsymbol{e_i}            
            \right)
        \end{equation*}
        где $\boldsymbol{e_i}$ -- собственные вектора для матрицы $A$, соответствующие собственному значению $\lambda_i$.
        Выражение 
        \begin{equation*}
            \sum_{i=1; i \neq m}^{n} \left(\dfrac{\lambda_m - \sigma_m}{\lambda_i - \sigma_m}\right)^k \xi_i \boldsymbol{e_i}
            \to 0, \text{ при } k \to \infty.
        \end{equation*}
        Выражение выше стремится к 0 из-за выбора собственного значения и приближения к нему, а значит 
        к 0 сойдется и элементы любого начальное приближения, соответствующих собственным векторам $\boldsymbol{e_i}, $ $ i \neq m$.
        В силу того, что любой собственный вектор задан с некоторой машинной погрешностью, то и 
        коэффициент $\xi_m$ при $\boldsymbol{e_m}$ будет отличен от 0, а значит метод обратной итерации будет сходиться к 
        собственному вектору $\boldsymbol{e_m}$, но медленнее.

        Рассмотрим метод обратной итерации, в котором использовано отношение Рэлея. 
        Пусть \mbox{$\sigma_0 \approx \lambda_m$}, $x_0^j$ -- собственный вектор, соответствующий собственному значению $\lambda_j \neq \lambda_m$,
        \begin{equation*}
            \sigma_1 = \dfrac{(Ax_0^j,\, x_0^j)}{(x_0^j,\, x_0^j)} \approx \lambda_j 
        \end{equation*}
        То есть получаем, что $\sigma_1 $ -- приближенное значение $\lambda_j$. 
        Тогда следующий вектор \mbox{$x_1 \approx (\lambda_j - \sigma_1)^{-k} \xi_j \boldsymbol{e_j}$}.
        То есть алгоритм будет сходиться к собственному значению $\lambda_j$, а следовательно, к собственному 
        вектору $x_0^j$, в силу того, что следующее приближение зависит только от начального приближения собственного вектора, а не от 
        начального приближения собственного значения. 

        \item Сформулируйте и обоснуйте критерий останова для QR-
        алгоритма отыскания собственных значений матрицы.
        \newline
        {\bfseries Ответ. } 
        Пусть 
        \begin{equation*}
            A_k = Q_k R_k,
        \end{equation*}
        считая $A_0 = A$.
        Тогда будем считать 
        \begin{equation*}
            A_{k+1} = R_{k} Q_{k}
        \end{equation*}
        Тогда критерием останова для заданного малого числа $\varepsilon$ 
        будем считать 
        \begin{equation*}
            \max_{0 \leqslant j<i<n} |a_{ij}| < \varepsilon
        \end{equation*}
        Тогда с заданной точностью можно утверждать, что $A_{k+1}$ является верхнетреугольной, а 
        следовательно собственные значения лежат на главной диагонале. 
        \item Предложите возможные варианты условий перехода к ал-
        горитму со сдвигами. Предложите алгоритм выбора вели-
        чины сдвига.
        \newline
        {\bfseries Ответ. } 
        Из теории известно, что элементы $a_{ij}^k$ матриц $A^k$, стоящие ниже главной диагонали, сходятся к нулю со скоростью геометрической прогрессии, знаменатель которой равен модулю отношения соответствующей пары собственных значений т.е.
	\[
	|a_{ij}^k|\le|\frac{\lambda_i}{\lambda_j}| \cdot |a_{ij}^{k-1}|
	\]
	Заметим, что если среди собственных чисел матрицы A есть
	близкие по величине, то есть для некоторых значений i и j $\frac{\lambda_i}{\lambda_j} \approx 1$, то сходимость будет очень медленной. Поэтому на практике часто используют алгоритм со сдвигами. В этом случае ищут собственные значения не матрицы A, а матрицы $A-\sigma E$, которые равны $\lambda_i - \sigma$. При таком подходе скорость сходимости QR-алгоритма определяется величиной $\frac{\lambda_i-\sigma}{\lambda_j- \sigma}$. Если $\sigma$ является хорошим приближением для $\lambda_i$, то это соотношение будет много меньше единицы и алгоритм будет быстро сходиться.
	
	
	
	Тогда, если нам известно например из теоремы о кругах Гершгорина как располагаются собственные значения, то если они близки к друг другу, то имеет смысл использовать метод сдвигов. Либо можно задать условие: если количество итераций либо количество умножение превышает некоторое пороговое значение, то начинаем использовать сдвиги. Также можно использовать условие, что если относительная величина нормы нижне треугольной части матрицы больше некоторого значения, то используем сдвиги.
	
	
	В качестве $\sigma$ при поиске $\lambda_i$ можно выбрать например $a_{ii}^k$ элемент на диагонали. Данное приближение будет не плохим т.к. с увеличением номера итерации элементы на диагонали матрицы приближаются ке соответствующим собственным значениям.

    
	Либо можно в качестве $\sigma$ выбрать значение, вычисленное по формуле Рэлея $\sigma_m = \frac{(Ae_m,e_m)}{(e_m,e_m)}$, где $e_m$ собственный вектор $e_m$ можно приближенно взять соответствующий вектор столбец из матрицы $R=R_k \cdot R_{k-1} \cdot R_1$. 
        \item Для чего нужно на каждой итерации нормировать приближение к собственному вектору?
        \newline
        {\bfseries Ответ. } 
        Пусть $\sigma_m$ -- приближенное число к некоторому собственному значению $\lambda_m$.
        Тогда рассмотрим 
        \begin{equation*}
            (A - \sigma_m E) y_{k+1} = x_k,
        \end{equation*}
        где $x_0$ --- некоторое начальное приближение.
        Тогда справедливо
        \begin{equation*}
            y_{k+1} = (A - \sigma_m E)^{-1} x_k
        \end{equation*}
        Заметим, что это эквивалентно 
        \begin{equation*}
            y_{k+1} = (A - \sigma_m E)^{-k} x_0
        \end{equation*}
        Для произвольного вектора $x$
        \begin{equation*}
            (A - \sigma_m E)^{-k} x = (\lambda_m - \sigma_m)^{-k} \left(
                \xi_m \boldsymbol{e_m} + \sum_{i=1; i \neq m}^{n} \left(\dfrac{\lambda_m - \sigma_m}{\lambda_i - \sigma_m}\right)^k \xi_i \boldsymbol{e_i}            
            \right) \approx (\lambda_m - \sigma_m)^{-k} \xi_m \boldsymbol{e_m}, k \gg 1 ,
        \end{equation*}
        где $\boldsymbol{e_i}$ -- собственные вектора для матрицы $A$, соответствующие собственному значению $\lambda_i$.

        Получается, что 
        \begin{equation*}
            y_{k+1} \approx (\lambda_m - \sigma_m)^{-k} \xi_m \boldsymbol{e_m}.
        \end{equation*}
        Тогда заметим, что по условию $\sigma_m$ достаточно хорошее приближение $\lambda_m$, значит 
        \mbox{$|\lambda_m - \sigma_m| \approx 0$}, а из этого следует, что $(\lambda_m - \sigma_m)^{-k}$ достаточно большое число. 
        Значит с каждой итерацией вектор $y_k$ будет сходиться к собственному вектору, но в силу неотнормированности, 
        он будет его модуль будет становиться значительно больше с каждой новой итерацией. Значит каждый раз будет 
        происходить деление на очень маленькое число в натуральной степени, что приведет к значительным ошибкам при вычислении. Тогда получается, 
        что необходимость нормировки приближения к собственному вектору вызвана повышением точности вычислений.

        \item Приведите примеры использования собственных чисел
        и собственных векторов в численных методах.
        \newline
        {\bfseries Ответ. } 
        Задача вычисления собственных значений возникает при: 1)Использовании метода главных компонент PCA для уменьшения размерности данных, сохраняя при этом основную информацию. 2) При решении систем дифференциальных уравнений с постоянными коэффициентами. 3) Решение уравнения Шредингера сводится к вычислению собственных значений для поиска спектра энергий волновой функции.
    \end{enumerate}  

\newpage
    \begin{table}[h!]
        \centering
        \caption{Количество итераций в зависимости от метода поиска собственных значений}
        \begin{tabular}{|c|c|c|}
        \hline
        & Со сдвигом & Без сдвига\\
        \hline 
        С приведением к форме Хессенберга &7 &33 \\ 
        \hline 
        Без приведения к форме Хессенберга & 9 &33 \\
        \hline
        \end{tabular}
    \end{table}
    \begin{table}[h!]
        \centering
        \caption{Количество операций умножения и деления в зависимости от метода поиска собственных значений}
        \begin{tabular}{|c|c|c|}
        \hline
        & Со сдвигом & Без сдвига\\
        \hline 
        С приведением к форме Хессенберга & 924 & 4592 \\ 
        \hline 
        Без приведения к форме Хессенберга & 2124 & 7884 \\
        \hline
        \end{tabular}
    \end{table}
    
\end{document}
